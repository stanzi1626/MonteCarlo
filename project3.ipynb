{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS20762 - Project 3 - Monte Carlo Method\n",
    "\n",
    "Alexander Stansfield <br>\n",
    "University of Manchester <br>\n",
    "May 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.constants as const\n",
    "\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s  = np.random.uniform(0, 1, 1000)\n",
    "count, bins, ignored = plt.hist(s, 15, density = True)\n",
    "plt.plot(bins, np.ones_like(bins), linewidth = 2, color = 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randssp(p,q):\n",
    "        \n",
    "    try: x\n",
    "    except NameError:\n",
    "        m = pow(2, 31)\n",
    "        a = pow(2, 16) + 3\n",
    "        c = 0\n",
    "        x = 123456789\n",
    "    \n",
    "    try: p\n",
    "    except NameError:\n",
    "        p = 1\n",
    "    try: q\n",
    "    except NameError:\n",
    "        q = p\n",
    "    \n",
    "    r = np.zeros([p,q])\n",
    "\n",
    "    for l in range (0, q):\n",
    "        for k in range (0, p):\n",
    "            x = np.mod(a*x + c, m)\n",
    "            r[k, l] = x/m\n",
    "    \n",
    "    return r\n",
    "\n",
    "k = randssp(3, 1500)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax1.scatter(k[0, :], k[1, :], k[2, :], color='r')\n",
    "\n",
    "number_points = 1000\n",
    "ax2.scatter(np.random.uniform(0, 1, number_points), np.random.uniform(0, 1, number_points), np.random.uniform(0, 1, number_points))\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_zlabel('z')\n",
    "\n",
    "ax1.view_init(elev = 10, azim = 56)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_MEAN_FREE_PATH = 0.45\n",
    "\n",
    "def random_exponential(mean_free_path, count):\n",
    "    return -mean_free_path*np.log(np.random.uniform(0, 1, count))\n",
    "\n",
    "def exponential_function(data, coefficient):\n",
    "    return 1/coefficient*np.e**(-data/coefficient)\n",
    "\n",
    "def find_parameters(x, y, yerr):\n",
    "    \"\"\"\n",
    "    Finds the best values for m_z, gamma_z and gamma_ee to have the\n",
    "    lowest chi-square. Halts code if no optimised parameters could be\n",
    "    found in the runtime allowed.\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    data: 2D array of floats\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    3 floats\n",
    "    \"\"\"\n",
    "    if yerr == 'a':\n",
    "        try:\n",
    "            expected, uncertainty = curve_fit(exponential_function, x, y) #, sigma=data[:, 2]\n",
    "        except RuntimeError:\n",
    "            print('Scipy.optimize.curve_fit was not able to find the best'\n",
    "                ' parameters')\n",
    "\n",
    "        return expected[0], math.sqrt(uncertainty[0, 0])\n",
    "    else:\n",
    "        try:\n",
    "            expected, uncertainty = curve_fit(exponential_function, x, y, sigma = yerr)\n",
    "        except RuntimeError:\n",
    "            print('Scipy.optimize.curve_fit was not able to find the best'\n",
    "                ' parameters')\n",
    "\n",
    "        return expected[0], math.sqrt(uncertainty[0, 0])\n",
    "\n",
    "\n",
    "count, bins, ignored = plt.hist(random_exponential(EXPECTED_MEAN_FREE_PATH, number_points), 15, density = True)\n",
    "bin_midpoints = 0.5*(bins[1:] + bins[:-1])\n",
    "free_path, uncertainty = find_parameters(bin_midpoints, count, 'a')\n",
    "plt.plot(np.linspace(0, np.max(bin_midpoints), 1000), exponential_function(np.linspace(0, np.max(bin_midpoints), 1000), free_path), color = 'red')\n",
    "print('Fitted mean free path is {0:.2f} \\pm {1:.3f} and mean free path coefficient put into random number generator is {2}'.format(free_path, uncertainty, EXPECTED_MEAN_FREE_PATH))\n",
    "\n",
    "plt.xlim(0, np.max(bin_midpoints))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "number_points = 10000\n",
    "\n",
    "def poles_gather():\n",
    "    theta = np.random.uniform(0, np.pi, number_points)\n",
    "    phi = np.random.uniform(0, 2*np.pi, number_points)\n",
    "    xdata = np.sin(theta)*np.cos(phi)\n",
    "    ydata = np.sin(theta)*np.sin(phi)\n",
    "    zdata = np.cos(theta)\n",
    "\n",
    "    return xdata, ydata, zdata\n",
    "\n",
    "def random_unit_sphere():\n",
    "    theta = np.arccos(1 - 2*np.random.uniform(0, 1, number_points))\n",
    "    phi = np.random.uniform(0, 2*np.pi, number_points)\n",
    "    xdata = np.sin(theta)*np.cos(phi)\n",
    "    ydata = np.sin(theta)*np.sin(phi)\n",
    "    zdata = np.cos(theta)\n",
    "\n",
    "    return xdata, ydata, zdata\n",
    "\n",
    "ax1.scatter(*poles_gather(), s=1)\n",
    "ax2.scatter(*random_unit_sphere(), s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "def normal_heat_map(axis, x_set, y_set, z_set):\n",
    "    '''\n",
    "    Function to generate a heat map from a given 3D datset.\n",
    "    Uses a gaussian fit to determine the density of the\n",
    "    values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : 2D array of floats\n",
    "        Entire dataset for a randomly gnerated 3d region\n",
    "        that follows a normal distribution.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \n",
    "    '''\n",
    "    density = gaussian_kde([x_set, y_set, z_set])([x_set, y_set, z_set])\n",
    "\n",
    "    idx = density.argsort()\n",
    "    x_set = x_set[idx]\n",
    "    y_set = y_set[idx]\n",
    "    z_set = z_set[idx]\n",
    "    density = density[idx]\n",
    "\n",
    "    axis.scatter(x_set, y_set, z_set, c=density, s=1)\n",
    "    axis.set_xlabel('x')\n",
    "    axis.set_ylabel('y')\n",
    "    axis.set_zlabel('z')\n",
    "\n",
    "normal_heat_map(ax1, *poles_gather())\n",
    "normal_heat_map(ax2, *random_unit_sphere())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "def isotropic_exponential_distribution(mean_free_path, quantity):\n",
    "    theta = np.arccos(1 - 2*np.random.uniform(0, 1, quantity))\n",
    "    phi = np.random.uniform(0, 2*np.pi, quantity)\n",
    "    random_exponential_magnitude = random_exponential(mean_free_path, quantity)\n",
    "    xdata = np.sin(theta)*np.cos(phi) * random_exponential_magnitude\n",
    "    ydata = np.sin(theta)*np.sin(phi) * random_exponential_magnitude\n",
    "    zdata = np.cos(theta) * random_exponential_magnitude\n",
    "\n",
    "    return xdata, ydata, zdata\n",
    "\n",
    "data = isotropic_exponential_distribution(EXPECTED_MEAN_FREE_PATH, number_points)\n",
    "ax1.scatter(*data)\n",
    "\n",
    "distance_data = np.sqrt(data[0]**2+data[1]**2+data[2]**2)\n",
    "count, bins, ignored = ax2.hist(distance_data, 15, density = True)\n",
    "bin_midpoints = 0.5*(bins[1:]+bins[:-1])\n",
    "free_path, uncertainty = find_parameters(bin_midpoints, count, 'a')\n",
    "ax2.plot(np.linspace(0, np.max(bin_midpoints), 1000), exponential_function(np.linspace(0, np.max(bin_midpoints), 1000), free_path), color = 'red')\n",
    "print('Fitted mean free path is {0:.3f} \\pm {1:.3f} and mean free path coefficient put into random number generator is {2}'.format(free_path, uncertainty, EXPECTED_MEAN_FREE_PATH))\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Simulation of Absorption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each material, we need to determine the macroscopic absorption and scattering cross sections, and the resultant total mean free path $\\lambda$. The macroscopic cross-section of an event, $\\Sigma$, is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Sigma = n\\sigma\n",
    "\\end{equation}\n",
    "\n",
    "where $n = \\frac{\\rho N_A}{M}$ and $\\sigma$ is the microscopic cross-section of the event. Using the values below for the properties of the materials, we can use equation (1) to find the macroscopic cross-section.\n",
    "\n",
    "\\begin{array}{c|ccc}\n",
    "    & \\text{Water} & \\text{Lead} & \\text{Graphite}\\\\ \\hline\n",
    "   \\text{Absorption}, \\sigma_a (barn) & 0.6652 & 0.158 & 0.0045\\\\\n",
    "   \\text{Scattering}, \\sigma_s (barn) & 103.0 & 11.221 & 4.74\\\\\n",
    "   \\text{Density}, \\rho (g/cm^3) & 1.00 & 11.35 & 1.67\n",
    "\\end{array}\n",
    "\n",
    "where the unit convesions to base units is $1\\text{barn} = 10^{-28}m^2$ and $1g/cm^3 = 10^{3}kg/m^3$. Let's store these values into dictionaries so that we can access them easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WATER_DICT = {'absorption_sigma': 0.6652e-28, 'scatter_sigma': 103.0e-28, 'density': 1.00e3, 'molar_mass': 18.01528e-3}\n",
    "LEAD_DICT = {'absorption_sigma': 0.158e-28, 'scatter_sigma': 11.221e-28, 'density': 11.35e3, 'molar_mass': 207.2e-3}\n",
    "GRAPHITE_DICT = {'absorption_sigma': 0.0045e-28, 'scatter_sigma': 4.74e-28, 'density': 1.67e3, 'molar_mass': 12.011e-3}\n",
    "MATERIALS_DICT = {'water': WATER_DICT, 'lead': LEAD_DICT, 'graphite': GRAPHITE_DICT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total macroscopic cross-section is $\\Sigma_T = \\Sigma_a + \\Sigma_s$ where $\\Sigma_a$ is the macroscopic cross-section for absorption events and $\\Sigma_s$ is the macroscopic cross-section for scattering events. To find the total mean free path, $\\lambda_T$ we use:\n",
    "\n",
    "The mean free path, average distance a particle will travel before encountering one of the events, is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\lambda = \\frac{1}{\\Sigma_T} = \\frac{1}{\\Sigma_a+\\Sigma_s}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macroscopic_cross_section(density, molar_mass, cross_section):\n",
    "    n = (density * const.N_A)/molar_mass\n",
    "    Sigma = n*cross_section\n",
    "    return Sigma\n",
    "\n",
    "def attenuation_calculation(Sigma_absorption, Sigma_scattering):\n",
    "    mean_free_path = 1/(Sigma_absorption + Sigma_scattering)\n",
    "    return mean_free_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the absorption and scattering cross sections, and the resultant total mean free path are found to be (which are then added to the material's dictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, material in MATERIALS_DICT.items():\n",
    "    material['macroscopic_absorption_area'] = macroscopic_cross_section(material['density'], material['molar_mass'], material['absorption_sigma'])\n",
    "    material['macroscopic_scatter_area'] = macroscopic_cross_section(material['density'], material['molar_mass'], material['scatter_sigma'])\n",
    "    material['mean_free_path'] = attenuation_calculation(material['macroscopic_absorption_area'], material['macroscopic_scatter_area'])\n",
    "    print('The macroscopic cross-section of absorption and scattering for {0} is: {1:.3f}, {2:.3f}. The total mean free path is {3:.3f}\\\n",
    "    '.format(name, material['macroscopic_absorption_area'], material['macroscopic_scatter_area'], material['mean_free_path']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each neutron travelling through the material, we will need to simulate it travelling a distance based off of the exponential probaility distrubution function defined above. After each step, we then generate a random number between 0 and 1. If the random number is less than probaility of absorption, $p_a = \\frac{\\Sigma_a}{\\Sigma_T}$, then the neutron is aborbed, otherwise it is scattered.\n",
    "\n",
    "Each neutron starts from one surface of the slab (take as x = 0), and then performs a random walk where each step is drawn from the distribution $e^{-\\frac{x}{\\lambda_T}}$, as above. After each step, you will need to check whether the neutron is absorbed in the slab, has escaped from the slab (x < 0 or x > T), or continues onto a following step. (Hint: Use a while loop, generating the entire set of steps and their locations; a flag variable is_absorbed can be set to 1 to tell the while loop to terminate, whilst another variable i can be used to keep track of how many steps have been taken. The while loop should be continued if all of these conditions are true: x > 0 or x<T then is_absorbed == 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_NEUTRONS = 100\n",
    "ITERATIONS= 10\n",
    "dead_particles = []\n",
    "\n",
    "class neutron():\n",
    "    def __init__(self, sigma_a: float, sigma_s: float, mean_free_path: float, thickness: float):\n",
    "        self.is_absorbed = False\n",
    "        self.is_backscattered = False\n",
    "        self.is_transmitted = False\n",
    "        self.sigma_a = sigma_a\n",
    "        self.sigma_s = sigma_s\n",
    "        self.mean_free_path = mean_free_path\n",
    "        self.thickness = thickness\n",
    "        self.x_position = random_exponential(mean_free_path, 1)\n",
    "        self.x_history = np.array([self.x_position])\n",
    "        \n",
    "    def timestep(self):\n",
    "        if np.random.uniform(0, 1, 1) < (self.sigma_a/(self.sigma_a+self.sigma_s)):\n",
    "            self.is_absorbed = True\n",
    "        else:\n",
    "            self.x_position += isotropic_exponential_distribution(self.mean_free_path, 1)[0]\n",
    "            self.x_history = np.append(self.x_history, self.x_position)\n",
    "            if self.x_position < 0:\n",
    "                self.is_backscattered = True\n",
    "            elif self.x_position > self.thickness:\n",
    "                self.is_transmitted = True\n",
    "\n",
    "def neutron_simulation_class(material:dict, thickness:float):\n",
    "    particle_behaviour_class = np.zeros((0, 3))\n",
    "    absorption_cross_section = material['macroscopic_absorption_area']\n",
    "    scattering_cross_section = material['macroscopic_scatter_area']\n",
    "    free_path = 1/(absorption_cross_section + scattering_cross_section)\n",
    "\n",
    "    for _ in range(ITERATIONS):\n",
    "        neutrons = [neutron(absorption_cross_section, scattering_cross_section, free_path, thickness) for _ in range(NUMBER_NEUTRONS)]\n",
    "        number_absorbed = 0\n",
    "        number_backscattered = 0\n",
    "        number_transmitted = 0\n",
    "        while len(neutrons) > 0:\n",
    "            for index, particle in enumerate(neutrons):\n",
    "                particle.timestep()\n",
    "                if particle.is_absorbed == True:\n",
    "                    number_absorbed += 1\n",
    "                    dead_particles.append(neutrons.pop(index))\n",
    "                elif particle.is_backscattered == True:\n",
    "                    number_backscattered += 1\n",
    "                    dead_particles.append(neutrons.pop(index))\n",
    "                elif particle.is_transmitted == True:\n",
    "                    number_transmitted += 1\n",
    "                    dead_particles.append(neutrons.pop(index))\n",
    "        particle_behaviour_class = np.vstack((particle_behaviour_class, np.array([number_absorbed, number_backscattered, number_transmitted])))\n",
    "    return(particle_behaviour_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_behaviour(particle_behaviour):\n",
    "    average_absorbed, average_absorbed_uncertainty = np.mean(particle_behaviour[:, 0]), np.std(particle_behaviour[:, 0])\n",
    "    average_backscattered, average_backscattered_uncertainty = np.mean(particle_behaviour[:, 1]), np.std(particle_behaviour[:, 1])\n",
    "    average_transmitted, average_transmitted_uncertainty = np.mean(particle_behaviour[:, 2]), np.std(particle_behaviour[:, 2])\n",
    "    return np.array([[average_absorbed, average_absorbed_uncertainty], [average_backscattered, average_backscattered_uncertainty], [average_transmitted, average_transmitted_uncertainty]])\n",
    "\n",
    "def print_average_behaviour(material_name:str, averages, thickness) -> None:\n",
    "    print('For {0} with a thickness of {1}m for {2} neutrons in {3} simulations, the behaviour of the neutrons is:'.format(material_name, thickness, NUMBER_NEUTRONS, ITERATIONS))\n",
    "    print('Average number of absorbed neutrons: {0:.2f} \\pm {1:.2f}'.format(averages[0, 0], averages[0, 1]))\n",
    "    print('Average number of backscattered neutrons: {0:.2f} \\pm {1:.2f}'.format(averages[1, 0], averages[1, 1]))\n",
    "    print('Average number of tranimtted neutrons: {0:.2f} \\pm {1:.2f}'.format(averages[2, 0], averages[2, 1]))\n",
    "    return None\n",
    "\n",
    "def behaviour_barplot(particle_behaviour):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    colours = ['red', 'green', 'blue']\n",
    "    label_names = ['Absorbed', 'Backscattered', 'Transmitted']\n",
    "    label_locations = np.linspace(0, 2.5, 3)  # the label locations\n",
    "    width = (1/ITERATIONS) # the width of the bars\n",
    "    for i in range(0, 3):\n",
    "        for j in range(ITERATIONS):\n",
    "            ax.bar(label_locations[i] - width/2 - (ITERATIONS/2 - 1)*width + j*width, particle_behaviour[j, i] / NUMBER_NEUTRONS, width, color = colours[i])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.xticks(label_locations, label_names, fontsize='17')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "def overall_behaviour(material_name:str, simulation_function, material_thickness):\n",
    "    behaviour = simulation_function(MATERIALS_DICT[material_name], material_thickness)\n",
    "    print_average_behaviour(material_name, average_behaviour(behaviour), material_thickness)\n",
    "    behaviour_barplot(behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLAB_THICKNESS = 0.1\n",
    "overall_behaviour('water', neutron_simulation_class, SLAB_THICKNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the history of the x position of each neutron is stored in the class, we can plot the x position of each neutron as a function of time (each timestep) and see how the system evolves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_path_plot(particles):\n",
    "    maximum = 0\n",
    "    for particle in particles:\n",
    "        if len(particle.x_history) > maximum:\n",
    "            maximum = len(particle.x_history)\n",
    "        plt.plot(np.linspace(0, len(particle.x_history), len(particle.x_history)), particle.x_history)\n",
    "        plt.scatter(len(particle.x_history), particle.x_history[-1])\n",
    "\n",
    "    plt.hlines(0, 0, maximum)\n",
    "    plt.hlines(SLAB_THICKNESS, 0, maximum)\n",
    "    plt.ylim(-SLAB_THICKNESS / 10, SLAB_THICKNESS + SLAB_THICKNESS / 10)\n",
    "    plt.xlim(0, maximum)\n",
    "    plt.show()\n",
    "\n",
    "particle_path_plot(dead_particles[-10:])\n",
    "particle_path_plot(np.take(dead_particles, np.random.randint(0, len(dead_particles), 20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the simulation faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutron_simulation_eff(sample_size:int, material:dict, thickness:float) -> tuple((int, int, int)):\n",
    "    \"\"\"\n",
    "    A more efficient version of the previous code using vectorization of functions\n",
    "    and using numpy instead of other function calls.\n",
    "    \"\"\"\n",
    "    sigma_a = material['macroscopic_absorption_area']\n",
    "    sigma_s = material['macroscopic_scatter_area']\n",
    "    mean_free_path = attenuation_calculation(sigma_a, sigma_s)\n",
    "    probability_absorption = sigma_a / (sigma_a + sigma_s) \n",
    "    absorbed = transmitted = backscattered = 0\n",
    "    \n",
    "    neutron_array = np.zeros((sample_size, 3))\n",
    "    neutron_array[:, 0] = random_exponential(mean_free_path, sample_size)\n",
    "\n",
    "    \n",
    "    while absorbed + transmitted + backscattered < sample_size:\n",
    "        neutrons_left = sample_size - transmitted - backscattered - absorbed\n",
    "\n",
    "        transmitted += len(np.argwhere(neutron_array[:, 0] >= thickness))\n",
    "        neutron_array = np.delete(neutron_array, np.argwhere(neutron_array[:, 0] >= thickness), axis = 0)\n",
    "        neutrons_left = sample_size - transmitted - backscattered - absorbed\n",
    "\n",
    "        random_reference = np.random.uniform(0, 1, neutrons_left)\n",
    "\n",
    "        absorbed += len(np.argwhere(random_reference < probability_absorption))\n",
    "        neutron_array = np.delete(neutron_array, np.argwhere(random_reference < probability_absorption), axis = 0)\n",
    "        neutrons_left = sample_size - transmitted - backscattered - absorbed\n",
    "        \n",
    "        backscattered += len(np.argwhere(neutron_array[:, 0] < 0))\n",
    "        neutron_array = np.delete(neutron_array, np.argwhere(neutron_array[:, 0] < 0), axis = 0)\n",
    "        neutrons_left = sample_size - transmitted - backscattered - absorbed\n",
    "\n",
    "        temp_x, temp_y, temp_z = isotropic_exponential_distribution(mean_free_path, neutrons_left)\n",
    "        neutron_array[:, 0] += temp_x\n",
    "        neutron_array[:, 1] += temp_y\n",
    "        neutron_array[:, 2] += temp_z\n",
    "\n",
    "    return (absorbed, backscattered, transmitted)\n",
    "\n",
    "def iterative_neutron_simulation_eff(material: dict, thickness:float):\n",
    "    particle_behaviour_eff = np.zeros((0, 3))\n",
    "    for _ in range(ITERATIONS):\n",
    "        particle_behaviour_eff = np.vstack((particle_behaviour_eff, neutron_simulation_eff(NUMBER_NEUTRONS, material, thickness))) #0 for water\n",
    "    return particle_behaviour_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_NEUTRONS = 15000\n",
    "overall_behaviour('water', iterative_neutron_simulation_eff, SLAB_THICKNESS)\n",
    "overall_behaviour('lead', iterative_neutron_simulation_eff, SLAB_THICKNESS)\n",
    "overall_behaviour('graphite', iterative_neutron_simulation_eff, SLAB_THICKNESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the variation in neutron transmission, reflection and absorption with slab\n",
    "thickness for the three materials. Determine the characteristic attenuation lengths for the\n",
    "three materials from the transmitted intensity, with estimated errors. Include a summary\n",
    "of numerical data and representative graphs.\n",
    "Hint: when fitting the transmitted neutron data you may have some thickness values\n",
    "giving zero transmitted neutrons, which will stop np.polyfit from working (log(0) = -\n",
    "Inf). You need to remove data points containing â€“Inf before fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 8))\n",
    "ax1 = fig.add_subplot(231)\n",
    "ax2 = fig.add_subplot(232)\n",
    "ax3 = fig.add_subplot(233)\n",
    "ax4 = fig.add_subplot(234)\n",
    "ax5 = fig.add_subplot(235)\n",
    "ax6 = fig.add_subplot(236)\n",
    "axes = np.array([[ax1, ax2, ax3], [ax4, ax5, ax6]])\n",
    "\n",
    "def linear_function(data, gradient, intercept):\n",
    "    return gradient*data + intercept\n",
    "\n",
    "def find_linear_parameters(x, y, yerr):\n",
    "    try:\n",
    "        expected, uncertainty = np.polyfit(x, y, 1, full = False, cov=True)\n",
    "    except RuntimeError:\n",
    "        print('Scipy.optimize.curve_fit was not able to find the best'\n",
    "              ' parameters')\n",
    "\n",
    "    return expected, uncertainty\n",
    "\n",
    "def varying_thickness(starting_thickness, ending_thickness, number_points):\n",
    "    index = 0\n",
    "    for material_name, material_dict in MATERIALS_DICT.items():\n",
    "        axes[0][index].set_title(material_name)\n",
    "        absorbed_behaviour = np.zeros((0, 2))\n",
    "        backscattered_behaviour = np.zeros((0, 2))\n",
    "        transmitted_behaviour = np.zeros((0, 2))\n",
    "        thickness_array = np.geomspace(starting_thickness, ending_thickness, number_points)\n",
    "        for material_thickness in thickness_array:\n",
    "            average_array = average_behaviour(iterative_neutron_simulation_eff(material_dict, material_thickness)) / NUMBER_NEUTRONS\n",
    "            absorbed_behaviour = np.vstack((absorbed_behaviour, average_array[0, :]))\n",
    "            backscattered_behaviour = np.vstack((backscattered_behaviour, average_array[1, :]))\n",
    "            transmitted_behaviour = np.vstack((transmitted_behaviour, average_array[2, :]))\n",
    "        axes[0][index].errorbar(thickness_array, absorbed_behaviour[:, 0], yerr = absorbed_behaviour[:, 1], color = 'red', label = 'Absorbed')\n",
    "        axes[0][index].errorbar(thickness_array, backscattered_behaviour[:, 0], yerr = backscattered_behaviour[:, 1], color = 'green', label = 'Backscattered')\n",
    "        axes[0][index].errorbar(thickness_array, transmitted_behaviour[:, 0], yerr = transmitted_behaviour[:, 1], color = 'blue', label = 'Transmitted')\n",
    "        axes[0][index].legend()\n",
    "\n",
    "        xdata = np.linspace(starting_thickness, ending_thickness, 10000)\n",
    "        parameters_linear, uncertainty_linear = find_linear_parameters(thickness_array, np.log(transmitted_behaviour[:, 0]), (1 / transmitted_behaviour[:, 0]) * transmitted_behaviour[:, 1])\n",
    "        mean_free_path_linear, mean_free_path_uncertainty_linear = parameters_linear[0], np.sqrt(uncertainty_linear[0, 0])\n",
    "        intercept, intercept_uncertainty = parameters_linear[1], np.sqrt(uncertainty_linear[1, 1])\n",
    "        print('{0:.3f} \\pm {1:.3f}'.format(-1 / mean_free_path_linear, (1 / (mean_free_path_linear**2))*mean_free_path_uncertainty_linear))\n",
    "        axes[1][index].errorbar(thickness_array, np.log(transmitted_behaviour[:, 0]), yerr = (1 / transmitted_behaviour[:, 0]) * transmitted_behaviour[:, 1], color = 'blue', label = 'Transmitted')\n",
    "        axes[1][index].plot(xdata, linear_function(xdata, mean_free_path_linear, intercept), 'k--')\n",
    "\n",
    "        index += 1\n",
    "\n",
    "varying_thickness(0.001, 0.2, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woodcock method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def real_step(particles, free_path, macroscopic_cross_sections, absorbed):\n",
    "    u = np.random.uniform(0, 1, len(particles))\n",
    "    probability_absorption = macroscopic_cross_sections[0] / np.sum(macroscopic_cross_sections)\n",
    "    absorbed += len(np.argwhere(u < probability_absorption))\n",
    "    particles = np.delete(particles, np.argwhere(u < probability_absorption), axis = 0)\n",
    "    particles += np.array(isotropic_exponential_distribution(free_path, len(particles))).T\n",
    "    return particles, absorbed\n",
    "\n",
    "def fictitious_step(current_position, previous_position, free_path):\n",
    "    difference_vector = np.add(current_position, previous_position*-1)\n",
    "    magnitude = np.sqrt(np.sum(difference_vector**2))\n",
    "    normalised_direction = difference_vector / magnitude\n",
    "    step = normalised_direction * random_exponential(free_path, len(normalised_direction))[:, None]\n",
    "    current_position += step\n",
    "    return current_position\n",
    "\n",
    "def Woodcock(sample_size: int, material_one: dict, material_two: dict, thickness_1: float, thickness_2: float):\n",
    "    '''\n",
    "    First we are assuming that Sigma_1 < Sigma_2 --> lambda_1 > lambda_2\n",
    "    '''\n",
    "    macroscopic_cross_sections1 = [material_one['macroscopic_absorption_area'], material_one['macroscopic_scatter_area']]\n",
    "    macroscopic_cross_sections2 = [material_two['macroscopic_absorption_area'], material_two['macroscopic_scatter_area']]\n",
    "    Sigma_1 = np.sum(macroscopic_cross_sections1)\n",
    "    Sigma_2 = np.sum(macroscopic_cross_sections2)\n",
    "    Sigma_T = np.max([Sigma_1, Sigma_2])\n",
    "\n",
    "    neutron_array = np.zeros((sample_size, 3))\n",
    "    neutron_array_previous_step = np.zeros((sample_size, 3))\n",
    "    neutron_array[:, 0] = random_exponential(1 / Sigma_1, sample_size)\n",
    "    neutrons_left = sample_size\n",
    "\n",
    "    number_absorbed = 0\n",
    "\n",
    "    probability_real_step = Sigma_1 / Sigma_T\n",
    "\n",
    "    while len(neutron_array) > 0:\n",
    "        v = np.random.uniform(0, 1, neutrons_left)\n",
    "        fictitious = fictitious_step(neutron_array[(v >= probability_real_step) & (neutron[:, 0] < 0.1)], neutron_array_previous_step[(v >= probability_real_step) & (neutron[:, 0] < 0.1)], 1 / Sigma_T)\n",
    "        real_material_1, number_absorbed = real_step(neutron_array[(v < probability_real_step) & (neutron[:, 0] < 0.1)], 1 / Sigma_1, macroscopic_cross_sections1, number_absorbed)\n",
    "        real_material_2, number_absorbed = real_step(neutron_array[neutron[:, 0] >= 0.1], 1 / Sigma_2, macroscopic_cross_sections2, number_absorbed)\n",
    "        neutron_array_previous_step = neutron_array.copy()\n",
    "        neutron_array = np.vstack((fictitious, real_material_1, real_material_2))\n",
    "        break\n",
    "\n",
    "Woodcock(10, MATERIALS_DICT['lead'], MATERIALS_DICT['water'], 0.1, 0.1)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b308f7c9fe9e9086965beb6dcb99c12ed5dceac295ff1a757b28faad7263d027"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
